# -*- coding: utf-8 -*-
"""weather prediction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f1mXaSaSjC9Ibq_X49OeQnodF1qySGAh
"""

#importing necessary libraries

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

#load the test dataset

weather_data  = pd.read_csv('Dataset11-Weather-Data.csv')
weather_data

weather_data.isnull().sum()

weather_data.shape

# to describe the given dataset
weather_data.describe()

weather_data.nunique()

print(weather_data.duplicated().sum())

weather_data.Weather.value_counts()

weather_data['Weather'].unique()

weather_data.Weather.nunique()

"""DATA STANDADIZATION"""

# Mapping weather descriptions into four broad categories: Clear, Cloudy, Rainy, Snowy
def categorize_weather(description):
    description = description.lower()
    if "clear" in description or "sunny" in description:
        return "Clear"
    elif "cloud" in description or "overcast" in description:
        return "Cloudy"
    elif "rain" in description or "drizzle" in description or "shower" in description:
        return "Rainy"
    elif "snow" in description or "ice" in description or "hail" in description:
        return "Snowy"
    else:
        return "Other"

# Apply the categorization
weather_data['Weather_Category'] = weather_data['Weather'].apply(categorize_weather)

# Display the first few rows to check the categorization
weather_data[['Weather', 'Weather_Category']].head()

weather_data['Weather_Category'].nunique()

weather_data.shape

weather_data.head()

# prompt: drop Date/Time

weather_data.drop(['Date/Time', 'Weather'], axis=1, inplace=True)
weather_data



"""**CHECKING OUTLAYERS AND HANDILING**"""

weather_data.head()

plt.figure()
plt.boxplot(weather_data['Temp_C'])
plt.title("boxplot")
plt.show()



plt.figure()
plt.boxplot(weather_data['Dew Point Temp_C'])
plt.title("boxplot")
plt.show()

plt.figure()
plt.boxplot(weather_data['Rel Hum_%'])
plt.title("boxplot")
plt.show()

plt.figure()
plt.boxplot(weather_data['Wind Speed_km/h'])
plt.title("boxplot")
plt.show()

plt.figure()
plt.boxplot(weather_data['Visibility_km'])
plt.title("boxplot")
plt.show()

plt.figure()
plt.boxplot(weather_data['Press_kPa'])
plt.title("boxplot")
plt.show()

q1 = weather_data["Rel Hum_%"].quantile(0.25)
q3 = weather_data["Rel Hum_%"].quantile(0.75)

iqr = q3 - q1

lower_bound = q1 - 1.5 * iqr
upper_bound = q3 + 1.5 * iqr


outliers=[]
for i in weather_data["Rel Hum_%"]:
   if i<lower_bound or i>upper_bound:
     outliers.append(i)
print(outliers)

weather_data["Rel Hum_%"] = weather_data["Rel Hum_%"].clip(lower=lower_bound,upper=upper_bound)

plt.figure()
plt.boxplot(weather_data['Rel Hum_%'])
plt.title("boxplot")
plt.show()

q1 = weather_data["Wind Speed_km/h"].quantile(0.25)
q3 = weather_data["Wind Speed_km/h"].quantile(0.75)

iqr = q3 - q1

lower_bound = q1 - 1.5 * iqr
upper_bound = q3 + 1.5 * iqr


outliers=[]
for i in weather_data["Wind Speed_km/h"]:
   if i<lower_bound or i>upper_bound:
     outliers.append(i)
print(outliers)

weather_data["Wind Speed_km/h"] = weather_data["Wind Speed_km/h"].clip(lower=lower_bound,upper=upper_bound)

plt.figure()
plt.boxplot(weather_data['Wind Speed_km/h'])
plt.title("boxplot")
plt.show()

q1 = weather_data["Visibility_km"].quantile(0.25)
q3 = weather_data["Visibility_km"].quantile(0.75)

iqr = q3 - q1

lower_bound = q1 - 1.5 * iqr
upper_bound = q3 + 1.5 * iqr


outliers=[]
for i in weather_data["Visibility_km"]:
   if i<lower_bound or i>upper_bound:
     outliers.append(i)
print(outliers)

weather_data["Visibility_km"] = weather_data["Visibility_km"].clip(lower=lower_bound,upper=upper_bound)

plt.figure()
plt.boxplot(weather_data['Visibility_km'])
plt.title("boxplot")
plt.show()

q1 = weather_data["Press_kPa"].quantile(0.25)
q3 = weather_data["Press_kPa"].quantile(0.75)

iqr = q3 - q1

lower_bound = q1 - 1.5 * iqr
upper_bound = q3 + 1.5 * iqr


outliers=[]
for i in weather_data["Press_kPa"]:
   if i<lower_bound or i>upper_bound:
     outliers.append(i)
print(outliers)

weather_data["Press_kPa"] = weather_data["Press_kPa"].clip(lower=lower_bound,upper=upper_bound)

plt.figure()
plt.boxplot(weather_data['Press_kPa'])
plt.title("boxplot")
plt.show()



"""**LABEL ENCODIND**"""

from sklearn.preprocessing import LabelEncoder

label_encoder = LabelEncoder()
weather_data['Weather_Category'] = label_encoder.fit_transform(weather_data['Weather_Category'])
weather_data.head()

from sklearn.preprocessing import StandardScaler

weather_data.head()

std_scaler=StandardScaler()
col=["Temp_C",	"Dew Point Temp_C",	"Rel Hum_%",	"Wind Speed_km/h",	"Visibility_km",	"Press_kPa"]
weather_data[col]=std_scaler.fit_transform(weather_data[col])

weather_data.head()

"""**EDA**

*Heat Map*
"""

plt.figure(figsize=(8, 6))
correlation_matrix = weather_data[['Temp_C',	'Dew Point Temp_C',	'Rel Hum_%',	'Wind Speed_km/h',	'Visibility_km',	'Press_kPa'	]].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Heatmap')
plt.show()

"""*histogram*"""

#histogram for Temperature
plt.figure(figsize=(10, 6))
plt.hist(weather_data['Temp_C'], bins=20, edgecolor='black', color='skyblue')
plt.title('Histogram of Temperature (°C)')
plt.xlabel('Temperature (°C)')
plt.ylabel('Frequency')
plt.grid(True)
plt.show()

#histogram for dew point
plt.figure(figsize=(10, 6))
plt.hist(weather_data['Dew Point Temp_C'], bins=20, edgecolor='black', color='green')
plt.title('Histogram of dew point')
plt.xlabel('dew point')
plt.ylabel('Frequency')
plt.grid(True)
plt.show()

#histogram for dew point
plt.figure(figsize=(10, 6))
plt.hist(weather_data['Rel Hum_%'], bins=20, edgecolor='black', color='red')
plt.title('Histogram of relative humidity')
plt.xlabel('Rel Hum_%')
plt.ylabel('Frequency')
plt.grid(True)
plt.show()

#histogram for dew point
plt.figure(figsize=(10, 6))
plt.hist(weather_data['Wind Speed_km/h'], bins=20, edgecolor='black', color='yellow')
plt.title('Histogram of Wind Speed_km/h')
plt.xlabel('Wind Speed_km/h')
plt.ylabel('Frequency')
plt.grid(True)
plt.show()

#histogram for dew point
plt.figure(figsize=(10, 6))
plt.hist(weather_data['Visibility_km'], bins=20, edgecolor='black', color='orange')
plt.title('Histogram of Visibility_km')
plt.xlabel('Visibility_km')
plt.ylabel('Frequency')
plt.grid(True)
plt.show()

#histogram for dew point
plt.figure(figsize=(10, 6))
plt.hist(weather_data['Press_kPa'], bins=20, edgecolor='black', color='indigo')
plt.title('Histogram of Press_kPa')
plt.xlabel('Press_kPa')
plt.ylabel('Frequency')
plt.grid(True)
plt.show()

# prompt: pairplot

sns.pairplot(weather_data, vars=['Temp_C', 'Dew Point Temp_C', 'Rel Hum_%', 'Wind Speed_km/h', 'Visibility_km', 'Press_kPa'], hue='Weather_Category')
plt.show()

"""x,y variables"""

x = weather_data.drop('Weather_Category', axis=1)
x

y = weather_data['Weather_Category']
y

weather_data.head()

"""**x,y spliting**"""

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=40)

x_train.shape,x_test.shape,y_train.shape,y_test.shape

# Check the shape of x and y before splitting
print("Shape of x:", x.shape)
print("Shape of y:", y.shape)

x_train.shape,x_test.shape,y_train.shape,y_test.shape

"""**1.DecisionTreeClassifier**"""

from sklearn.tree import DecisionTreeClassifier
decision_tree_model = DecisionTreeClassifier()

decision_tree_model.fit(x_train, y_train)

y_pred = decision_tree_model.predict(x_test)

from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

accuracy_score(y_test, y_pred)

"""**2.KNeighborsClassifier**"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score


kn_model=KNeighborsClassifier()
kn_model.fit(x_train,y_train)

y_pred = kn_model.predict(x_test)

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')

# Print the metrics
print(f"Accuracy: {accuracy:.2f}")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1 Score: {f1:.2f}")

"""**3.Support Vector Machine (SVM)**"""

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
model_svc=SVC()
model_svc.fit(x_train,y_train)
y_pred = model_svc.predict(x_test)

# Calculate metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')

# Print the metrics
print(f"Accuracy: {accuracy:.2f}")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1 Score: {f1:.2f}")

"""**4.RandomForestClassifier**"""

from sklearn.ensemble import RandomForestClassifier


rf_model = RandomForestClassifier()
rf_model.fit(x_train, y_train)


y_pred = rf_model.predict(x_test)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score


rf_model = RandomForestClassifier()
rf_model.fit(x_train, y_train)

# Predict the test set
y_pred = rf_model.predict(x_test)

# Calculate metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')

# Print the metrics
print(f"Accuracy: {accuracy:.2f}")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1 Score: {f1:.2f}")

"""**5.Logistic Regression**"""

from sklearn.linear_model import LogisticRegression

logistic_model = LogisticRegression(max_iter=1000)  # Increase max_iter if needed

# Train the model
logistic_model.fit(x_train, y_train)

# Make predictions
y_pred = logistic_model.predict(x_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')

# Print the metrics
print(f"Accuracy: {accuracy:.2f}")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1 Score: {f1:.2f}")

"""**6.GradientBoostingClassifier(GBM)**"""

from sklearn.ensemble import GradientBoostingClassifier

gb_model = GradientBoostingClassifier()

# Train the model
gb_model.fit(x_train, y_train)

# Make predictions
y_pred = gb_model.predict(x_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')

# Print the metrics
print(f"Accuracy: {accuracy:.2f}")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1 Score: {f1:.2f}")

"""**7.GaussianNB**"""

from sklearn.naive_bayes import GaussianNB

# Create a Naive Bayes model
nb_model = GaussianNB()

# Train the model
nb_model.fit(x_train, y_train)

# Make predictions
y_pred = nb_model.predict(x_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')

# Print the metrics
print(f"Accuracy: {accuracy:.2f}")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1 Score: {f1:.2f}")

from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [5, 10, 15],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}


rf_model = RandomForestClassifier()

# Create GridSearchCV object
grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='accuracy')

# Fit the grid search to the data
grid_search.fit(x_train, y_train)

# Get the best parameters
best_params = grid_search.best_params_
print("Best parameters:", best_params)

# Get the best score
best_score = grid_search.best_score_
print("Best score:", best_score)
# Train the model with the best parameters
best_rf_model = RandomForestClassifier(max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=100)
best_rf_model.fit(x_train, y_train)

# Make predictions with the best model
y_pred = best_rf_model.predict(x_test)

# Evaluate the best model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Calculate the confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Print the confusion matrix
print("Confusion Matrix:")
print(cm)

# Visualize the confusion matrix (optional)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.title("Confusion Matrix")
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.show()

# prompt: app.pickle

import pickle

# Assuming 'best_rf_model' is your trained model
filename = 'app.pickle'
pickle.dump(best_rf_model, open(filename, 'wb'))